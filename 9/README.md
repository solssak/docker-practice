## 1. 최종: Docker 컨테이너 배포하기
로컬 머신을 넘어 실제 리모트 머신에서도 컨테이너를 실행하는 것이 목표이며,   
사용자들이 웹에서 접근 가능한 형태로 프로덕션 환경을 구성할 것.

**=> 도커의 진짜 쓰임새를 체험하자!**

### 🚀 이번 시간에 다루게 될 시나리오
- 리모트 호스트에 컨테이너를 띄우는 법
- 배포할 때 고려해야 할 설정과 보안
- Docker Audit 설치 및 운영
- 수동 관리와 관리형 서비스의 차이
- 실전에서 마주치는 수많은 문제 해결 시나리오..

### 개발에서 프로덕션으로, 컨테이너의 진짜 여행
이미 컨테이너가 얼마나 유용한지 경험했다. 개발 환경을 빠르게 설정하고,    
격리된 상태에서 안정적으로 크드를 실행할 수 있었다.

하지만 어디까지나 **개발 환경**에서의 이야기였다.
이번 시간에 그 다음 단계인 **배포**로 넘어가려 한다.

### 컨테이너는 단순한 개발 도구가 아니다
도커 컨테이너는 코드 뿐만 아니라, 그 코드가 작동하기 위한 모든 환경을 함께 담고 있다.   
이 말은 곧, 도커가 설치되어있는 곳이라면 어디에서든 동일하게 실행될 수 있다는 뜻.

이게 왜 중요할까?

현실에서는 로컬 환경에서 잘 동작하던 앱이,   
리모트 서버에 올리면 이유 없이 작동하지 않는 일이 있기 때문이다.   

하지만 컨테이너를 사용하면, 로컬에서 잘 작동하던 그대로를   
리모트 서버로 옮겨도 똑같이 작동시킬 수 있다.

Node.js든, Python이든, PostgreSQL이든   
리모트 머신에 직접 설치할 필요가 없다.

컨테이너 내부에 모든 환경이 포함되어 있기 때문에   
배포시에 컨테이너만 있으면 해결이 된다.   

이건 단순히 "편하다"를 넘어   
예측 가능성, 재현성, 확장성을 보장해준다.

### 그런데, 개발과 배포는 조금 다르다!
개발할 때 자주 쓰던 바인트 마운트 - 파일을 실시간으로 수정하고, 바로 컨테이너에 반영되게 해주는 기능.   
하지만 프로덕션 환경에서는 바인드 마운트를 사용하면 안된다.   
보안, 안정성, 일관성 측면에서 문제가 될 수 있기 때문이다.   
왜 그런지, 그리고 어떻게 대체할 수 있을지 알아보자.

### 다중 컨테이너?
간단한 서비스는 하나의 컨테이너로도 충분하지만,   
실제 서비스를 운영하다 보면 DB, 백엔드, 프론트엔드, 캐시 등   
여러 개의 컨테이너로 구성된 구조가 필요해진다.

이런 다중 컨테이너 앱을 어떻게 관리하고 배포할지   
그리고 여러 리모트 호스트에 나눠 배포할 수 있는 지 알아보자.

### 완전한 통재 vs 적절한 위임
한가지 더 고민해볼만한 게 있다.
리모트 머신을 내가 관리할 것인지,   
아니면 AWS 같은 클라우드 서비스에 일부 통제권을 넘기고 관리의 부담을 줄일 것인지.

직접 관리하면 자유도는 높지만,   
보안, 성능, 가용성 등 모든 것을 직접 세팅해야한다.

반면, 관리형 서비스(AWS 등)는 제한은 적지만 책임도 적다.   
상황에 따라 이 방식이 현명할 수도 있다.   

이 상황을 판단할 수 있는 기준에 대해서도 알아보자.

### 이번 시간의 최종 목표는?
> “로컬에서 개발하던 컨테이너를, 리모트 환경에서도 문제없이 작동하도록 만드는 것.”
- 개발과 배포 환경의 차이를 이해하고
- 컨테이너 환경을 일관되게 유지하며
- 다중 컨테이너로 프로젝트를 구성하고
- 관리형 배포 전략에 대해 고려해보자.

=> 컨테이너가 단순한 개발 보조 도구가 아니라,
진짜 '서비스를 운영하기 위한 인프라의 핵심'임을 체감해보자."

## 2. AWS EC2에 기본 Node.js 앱 배포하기
일단 DB, 프론트를 고려하지 않고 단순한 Node.js 앱 하나로 시작하자.

### EC2란?
AWS의 EC2(Elastice Compute Cloud)는   
쉽게 말해, 클라우드 위에 띄우는 나만의 리눅스 컴퓨터이다.
- 인터넷만 있다면 어디서든 접근 가능하고,
- 내가 원하는 소프트웨어를 설치하고,
- 애플리케이션을 실행할 수 있다.
이 EC2 인스턴스에 Docker를 설치하고,
그 위에서 컨테이너를 실행하게 될 것.

### 배포 흐름 잡기
1. EC2 인스턴스 생성
  - 리모트 서버를 생성하는 것.
  - VPC와 Security Group을 함께 구성.
  - Security Group을 통해 어떤 포트를 외부에 노출할지 결정.
3. SSH로 EC2에 접속
  - Secure Shell: 터미널 기반으로 원격 컴퓨터에 접속할 수 있는 방식.
  - 직접 명령어를 입력하며 Docker를 설치하고 컨테이너를 실행.
5. 도커 컨테이너 실행
  - 앱을 빌드한 뒤,
  - Docker Hub에 이미지를 업로드하고
  - 리모트 서버에서 이미지를 내려받아 실행.

### 도커 이미지 빌드 & 실행
강의에 첨부된 파일을 다운 받고 이미지를 빌드 & 실행해보자.
1. 도커 이미지 빌드
```
docker build -t node-dep-example .
```
2. 도커 컨테이너 실행
```
docker run -d --rm -p 80:80 --name node-dep node-dep-example
```
3. localhost에 접속
`welcom.html`이 보이면 성공

### 개발 vs 배포 - 같은 컨테이너, 다른 방식
>  `docker run`명령어로 로컬에서 컨테이너를 실행했다.   
> 그런데, 이번에는 바인드 마운트가 포함되어있지 않았다.
> 
> 우리가 지금 실행한 앱이 **프로덕션 배포용**이기 때문!

개발중엔 바인드 마운트가 필요하다.
컨테이너를 매번 빌드하거나 재시작하는 것을 하지 않기 위헤   
`-v`를 사용해 로컬 프로젝트 폴더를 컨테이너 내부 디렉토리에 **실시간 연결** 해주는 방식이다.

즉, 로컬에서 파일을 수정하면   
컨테이너는 자동으로 그 최신 코드를 반영하게 되는 것.   
덕분에 이미지를 다시 빌드하거나 컨테이너를 재시작하지 않아도 됨.

하지만 프로덕션에서는 다르다.
- 리모트 서버엔 개발자의 코드 폴더(디렉토리)가 존재하지 않기 때문
- 바인드 마운트를 사용하면 결국 서버 자체를 구성해야한다.
- 그럼 컨테이너가 **자체 환경을 캡슐화 한다는 원칙에 위배됨!**

그렇다면 어떻게 해야하나? -> **COPY**를 사용합니다!
```
COPY . /app
```
Dockerfile에는 보통 이런 명령이 있다.   
이게 의미하는건, 소스 코드를 이미지에 그대로 복사한다는 것.

이렇게 하면, 이미지를 빌드한 시점의 코드와 실행 환경이   
모두 하나의 이미지 안에 포함되게 된다.   
그리고 이 이미지를 리모트 서버에서 가져오기만 하면   
주변에 아무 설정 없이도 그대로 실행할 수 있는 것.

**- 바인드 마운트 vs COPY**
| 개발 환경                                | 프로덕션 환경                                  |
|------------------------------------------|------------------------------------------------|
| `-v ./src:/app/src` (바인드 마운트) 사용 | `COPY . /app` (Dockerfile 내 COPY 사용)       |
| 실시간 코드 반영                         | 정적인 코드 포함                               |
| 빠른 피드백 / 테스트                    | 재현 가능하고 독립적인 실행 환경              |
| 이미지 재빌드 불필요                     | 이미지 빌드 후 배포 필요                       |
| 유연하지만 일시적                        | 견고하고 신뢰할 수 있음                        |

정리하면, 
컨테이너의 핵심은 **이식성**과 **재현성**이다.   
어디에서 실행하든 - 내 컴퓨터든, 팀원의 컴퓨터든, AWS 든,
항상 같은 결과를 내야한다.

그러기 위해서는,   
코드와 환경이 완전히 캡슐화된 하나의 이미지로 존재해야하고,   
그 안에 모든 것이 포함되어야 한다.

그것이 바로 도커의 철학이고,   
우리가 프로덕션에서 바인드 마운트를 사용하지 않는 이유다.

### 이제 진짜 웹에 올려보기
1. 코드를 수정하고
2. 이미지를 다시 빌드하고
3. 빌드된 이미지를 원격 서버에서 실행한다.

이제 까지는 이 과정을 모두 로컬에서 진행했지만,
이제는 이 이미지를 EC2 리모트 서버에서 실행할 것이다.

세팅 과정 정리
1. `Amazon Linux AMI 64-bit x86` 선택 (운영체제)
2. 인스턴스 타입 `t3.micro` -> RAM과 CPU가 제한적이지만 무료 버전이니 사용!
3. VPC(Virtual Private Cloud) 자동 생성되어 있다면 그대로 사용 -> 없다면 새로 생성하기!
  - 대부분의 설정은 기본값으로 유지해도 충분함.
4. Key Pair - SSH 연결을 위한 열쇠
  - 'Create new key pair'
  - `.pem` 파일은 절대 공유 X, 재다운로드 안됨(새로 인스턴스 생성해야됨)
5. 인스턴스 실행 및 확인
6. SSH 접속 - 로컬에서 서버에 연결하기
  - `.pem` 키 파일이 있는 폴더에서 터미널 실행
  - `chmod 400 example-1.pem`, `ssh -i "example-1.pem" ec2-user@<EC2 퍼블릭 IP 주소>`

다음은 **EC2에 Docker를 직접 설치**하는 단계이다.   
생성한 컨테이너 이미지를 이 서버에서 실행하기 위한 필수 준비 작업.

```amazon-linux-extras install docker``` 과거에는 해당 명령어를 사용했지만,   
Amazon Linux 2 또는 최신 버전에서는 동작하지 않는다고 한다.
[참조](https://stackoverflow.com/questions/53918841/how-to-install-docker-on-amazon-linux2/61708497#61708497)

```bash
# 1. 시스템 업데이트
sudo yum update -y

# 2. Docker 설치
sudo yum -y install docker

# 3. Docker 서비스 시작
sudo service docker start

# 4. 현재 사용자(ec2-user)를 docker 그룹에 추가
sudo usermod -a -G docker ec2-user
```
`usermod`명령어로 docker 그룹에 추가한 후에는   
현재 SSH세션에는 반영되지 않는다고 한다.   
따라서 로그아웃 했다가 다시 로그인해야 변경 사항이 적용된다.
```
sudo systemctl enable docker // 재접속할 때마다 Docker가 자동 실행 되게 설정
docker version
```
이후 아래 명령어를 입력하고, 버전 확인이 가능하면 웹에 node.js를 올릴 준비가 되었다.

이제 Docker가 설치된 EC2 인스턴스에 우리가 만든 Node.js Docker 애플리케이션 이미지를 전달해야한다.   
방법은 크게 2가지가 있다.   
1. 리모트에서 빌드하는 방식 (불필요하게 
   - 소스 코드 전체를 EC2로 복사
   - 거기서 `docker build`로 이미지 생성
   - `docker run`으로 실행
     - 불필요하게 복잡하고, 특히 보안, 빌드 환경 문제로 비효율적임
2. 로컬에서 빌드 -> Docker Hub 푸시 -> EC2에서 pull
   - 로컬에서 이미지를 빌드하고
   - Docker Hub에 푸시
   - EC2에서 `docker pull` 후 `docker run`
     - 협업이나 CI/CD에도 이상적

2번째 방법으로 차근차근 해보면,
1. Docker Hub에 저장소 만들고
2. `dockerignore`파일을 설정해 `node_modules`, `Dockerfile`, `*.pem`파일을 추가해준다.
3. 이미지 빌드 및 태그 설정
   ```
   # 이미지 빌드
   docker build -t node-dep-example-1 .

   # Docker Hub용 태그 추가 (형식: 사용자명/저장소명)
   docker tag node-dep-example-1 academind/node-example-1
   ```
4. 이미지 푸시
   ```
   docker push solssak/node-docker-1
   ```
Docker Hub에 푸시가 되었다면 EC2 인스턴스에서 해당 이미지를 실행할 수 있다!
이후 아래 명령어로 해당 이미지를 실행할 수 있게 된다.
```
docker pull solssak/node-example-1
docker run -d -p 80:80 solssak/node-example-1
```
이렇게 하면 전 세게 어디에서나   
브라우저로 EC2 퍼블릭IP에 접속해 우리의 앱을 확인해볼 수 있다.

**주의할점**
EC2에서 `pull`명령어를 입력했을 때 아래 에러가 발생할 수 있다.
> docker: no matching manifest for linux/amd64 in the manifest list entries.

EC2 인스턴스에서 사용하는 CPU 아키텍쳐(amd64(에 맞는 Docker 이미지가 Docker Hub 저장소에 존재하지 않는다는 뜻이다.   
로컬에서 `docker build`시에 M1같은 ARM 환경에서는 `linux/amd64`아키텍쳐로 이미지가 생성된다.   
그런데 EC2 인스턴스는 일반적으로 `amd64`기반이다.   
따라서 Docker Hub에 업로드된 이미지가 `arm64`전용일 경우에 EC2에서 `pull`할 수 없고, 저 오류가 발생한다.   

해결 방법으로는 1. `amd64` 이미지로 재빌드 2. 멀티 아키텍쳐 이미지로 빌드 하는 방법이 있는데,   
범용성 측면에서 2번이 유리하다고 생각했다.
```
docker buildx build --platform linux/amd64,linux/arm64 -t solssak/node-docker-1 . --push
```

마지막 단계로 인바운드 HTTP를 허용해야한다.
1. EC2 콘솔 -> 인스턴스 -> 보안 그룹에서
2. 하단 인바운드 규칙 생성
   Type: HTTP
   Port: 80 (자동)
   Source: Anywhere(IPv4)
3. 저장

### 정리
- EC2 인스턴스에는 Node.js, npm 등 아무것도 설치하지 않았다.
- 오직 `docker`만 설치했다.
- 그럼에도 불구하고 Node.js 앱이 실행되고, 웹으로도 접속할 수 있다.
