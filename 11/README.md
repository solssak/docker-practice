### 1. Kubernetes

kubernetes란 단일 소프트웨어가 아니라 시스템  
컨테이너 배포에 도움이 되는 것, 도구 및 작업 방법들의 모음임 - by 공식문서

이 문장만으로는 kubernetes가 왜 필요한지, 어떤 문제를 해결하는지 정확히 감이 오지 않는다.

그러니 한 발 물러서서, 컨테이너를 수동으로 배포했을 떄 생기는 문제를 먼저 살펴보자.

1-1. 수동 배포의 문제점
직접 EC2 인스턴르르 만들고, 거기에 Docker를 설치해서 컨테이너를 실행한다고 가정해보자.  
이럴 때 생기는 문제는 다음과 같다.

- 컨테이너 장애 감지 및 복구
  - 컨테이너가 죽으면 사람이 직접 감지하고, 다시 띄워야 함
- 스케일링 (트래픽 증가/감소 대응)
  - 트래픽이 늘면 수동으로 컨테이너를 여러개 띄워야하고, 줄면 줄여야함
- 로드 밸런싱 (트래픽 분산)
  - 컨테이너가 여러 개 떠 있으면, 들어오는 요청을 컨테이너에 골고루 분산시켜야함.
- 서버 운영 및 보안 관리
  - EC2 인스턴스의 OS 업데이트, 보안 패치, 설정 관리도 직접 해야함

1-2. 수동 관리가 힘든 이유
서버와 컨테이너를 일일이 수동으로 관리하는 것은 사람이 하기 어려움  
(사람이 24시간 컨테이너를 모니터링 할 수 없기에)
앱이 커질수록, 사용자 수가 많아질 수록 문제는 더 심각해짐

1-3. 그래서 kubernetes가 필요
kubernetes는 이런 문제를 해결한다.

- 컨테이너 충돌 감지 -> 자동 복구
  - 트래픽 증가 -> 자동으로 컨테이너 추가
  - 트래픽 감소 -> 자동으로 컨테이너 제거
  - 로드밸런싱 -> 자동으로 요청 분배
    **- 즉, 사람이 직접 서버와 컨테이너를 돌보지 않아도 되게 만들어주는 시스템**

> kubernetes는 수동으로 관리하기 어려운 컨테이너 배포, 복구, 스케일링, 로드밸런싱 문제를 해결하는 시스템이다.

### 2. 왜 Kubernetes인가?

예전 Docker 배포 섹션에서 사용한 ECS 같은 서비스가 이런 문제를 해결하는데 도움이 된다.

2-1. ECS가 해결하는 것

- 컨테이너 헬스체크와 자동 재시작
  -> 컨테이너가 죽으면 자동으로 다시 띄워줌
- 오토 스케일링
  -> 트래픽 증가/감소에 따라 컨테이너 인스턴스 수를 자동 조정
- 로드 밸런싱
  -> 여러 컨테이너 인스턴스에 트래픽을 균등하게 분산.

=> 즉, 수동 배포 시 발생하는 주요 문제를 ECS가 해결해줌

2-2. ECS의 한계점 (클라우드 락인)

- ECS는 AWS 전용
- 클러스터, 태스크, 서비스 등 AWS가 정의한 방식에 따라야 한다
- CLI나 설정 파일을 통해 구성할 수도 있지만, 그 파일들도 AWS 전용 포맷임
- 만약 다른 클라우드로 넘어가고 싶으면?
  -> 기존 설정을 버리고 처음부터 다시 시작해야함

=> ECS는 좋은 기능이지만, AWS에 종속적이다.

2-3. 그래서 Kubernetes가 등장함

- kubernetes는 특정 클라우드 서비스에 묶이지 않는다
- AWS, GCP, Azure, 온프레미스 어디서든 동일한 방식으로 사용할 수 있다
- 벤더에 종속되지 않고, **이식성과 유연성**을 갖는다.

### 3. Kubernetes가 무엇인가?

3-1. Kubernetes가 하는 일

- 컨테이너 배포 관리
- 컨테이너 스케일링
- 컨테이너 상태 모니터링 및 자동 복구
- 로드 밸런싱
- 배포를 구성 파일로 표준화해서 관ㄹ

**=> 즉, 사람이 수동으로 해야할 컨테이너 운영을 자동화하는 오픈소스 시스템**

3-2. Kubernetes의 특징

- 클라우드 독립적
  - AWS, Azure, GCP, 온프레미스 어디서나 사용 가능
- 표준화된 구성 파일을 사용
  - 클라우드 서비스 종속 없이 동일한 yaml 파일로 배포를 정의할 수 있음
- 특정 클라우드 서비스가 아님
  - AWS ECS 같은 '서비스'가 아니라, 오픈소스 소프트웨어/시스템
- Docker의 대체제가 아님
  - Docker와 함께 사용한다. Docker 컨테이너를 kubernetes가 관리하는 구조
- 비용이 없음
  - Kubernetes 자체는 무료, 다만 리소스(서버 등)는 클라우드 요금이 발생할 수 있음
- 여러 머신을 관리할 수 있다.
  - 로컬 Docker Compose가 단일 머신을 관리했다면, kubernetes는 다중 머신을 통합해서 관리할 수 있다

> kubernetes는 여러 머신에서 컨테이너를 자동 배포, 확장, 복구하는 "멀티 머신용 docker-compose" 같은 오픈 소스 시스템이다.

> Docker = "컨테이너를 만들고 실행하는 기술"
> Docker Compose = "내 로컬에서 여러 컨테이너를 관리하는 스크립트"
> kubernetes = "여러 대의 서버(머신) 위에 컨테이너를 알아서 깔고, 켜고, 껐다 켰다, 늘리고 줄이는 자동화 시스템"

4. Kubernetes 기본 아키텍쳐 요약

4-1. Pod

> 컨테이너를 감싸는 kubernetes의 포장 박스

- kubernetes에서 가장 작은 배포 단위.
- 하나 이상의 컨테이너를 감싼다. (보통 하나의 컨테이너를 가짐)
- kubernetes 구성 파일에서 정의한다.
- 포드는 항상 워커 노드 위에서 실행된다.

4-2. Worker Node

> 컨테이너(포드)를 실제로 돌리는 서버

- 포드를 실행하는 실제 머신 (서버, 가상머신)
- CPU, 메모리 자원을 가지고 있음
- 하나의 워커 노드에 여러 포드를 실행할 수 있음.
- 워커 노드에는 프록시도 설치되어 트래픽을 포드로 연결해줌.

4-3. Master Node (Control Plane)

> 모든 워커 노드와 포드를 조종하는 컨트롤타워

- 전체 클러스터를 관리하는 컨트롤 센터
- 포드를 생성하거나 삭제하고, 워커 노드에 명령을 내림
- 실질적으로는 여러 컴포넌트(Controller, Scheduler, API Server 등)로 구성
- 일반적으로 워커 노드와 분리되어 별도 머신에서 운영하지만, 테스트용으로 하나의 서버에서 둘 다 돌리기도 함

4-4. Cluster

> 마스터 + 워커들이 모여 있는 kubernetes 집단

- 하나 이상의 마스터 노드 + 여러 워커 노드가 함께 이루는 하나의 큰 시스템.
- kubernetes에서는 이 전체 묶음을 클러스터라고 부른다.
- 마스터가 워커 노드들을 제어하면서, 애플리케이션이 실행된다.

4-5. 정리

> kubernetes는 마스터 노드가 여러 워커 노드 위에 포드를 관리하며, 이 모든 걸 클러스터라는 큰 네트워크로 묶어 운영하는 시스템

```
[Master Node] // 마스터가 워커를 관리
    ↓ (명령)
[Worker Node]  --  [Pod]  --  [Container] // 워커는 포드를 띄우고 포드는 컨테이너를 실행
[Worker Node]  --  [Pod]  --  [Container]
[Worker Node]  --  [Pod]  --  [Container]
```

- kubernetes는 우리가 직접 포드를 하나하나 실행시키지 않는다
- 대신 "원하는 상태"(예: 컨테이너 3개 띄워줘)를 선언하고
- kubernetes가 알아서 그 상태를 맞추려고 노력한다.
  **-> (→ 이걸 "선언적(Declarative) 관리" 라고 부릅니다.)**

### 4. Kubernetes에 대해 유의할 점

4-1. Kubernetes는 "환경"을 직접 만들어주지 않는다.

- kubernetes는 컨테이너를 관리하고 운영하는 시스템
- 하지만 클러스터(마스터 + 워커)를 직접 생성하거나, 셋업하지 않음
- 클러스터를 구성할 머신, 인스턴스, 리소스(로드 밸런서, 스토리지 등)은 우리가 준비해야함.

4-2. 개발자가 직접 해야 하는 것

- 워커 노드와 마스터 노드를 만들로 준비해야함
- 필요한 kubernetes 소프트웨어(예: kubelet, kube-proxy, kube-apiserver 등)를 설치해야함
- 클라우드 리소스 (EC2 인스턴스, 로드밸런서, 볼륨 등)를 필요에 따라 추가 설정해야 한다.

=> 즉, kubernetes는 준비된 리소스를 가지고만 일할 뿐, 리소스를 대신 준비해주지 않는다.

4-3. 준비가 끝난 이후

- kubernetes는
  - pod 생성
  - container 생성
  - 장애 감지
  - 실패한 컨테이너 재실행
  - 스케일 자동 조정
  - 트래픽을 로드밸런싱함

=> 즉, 실제 컨테이너 관리는 kubernetes가 전부 맡아줌

4-4. 비유

- Docker Compose도 로컬에 Docker를 설치해주지 않는다.
- Docker Compose는 "이미 Docker가 설치된 환경"을 가정하고, 거기서 컨테이너를 관리하는 것처럼,
- kubernetes도 "이미 준비된 클러스터"를 가정하고, 거기서 pod/container를 관리

> kubernetes는 클러스터를 직접 만들어주지 않고, 준비된 환경에서 컨테이너를 자동으로 관리하는 시스템이다.

### 5. Worker node

> 워커 노드는 포드를 실행하고, 마스터 노드의 지시에 따라 컨테이너를 돌리는 쿠버네티스 클러스터의 일꾼

5-1. 기본 개념

- Worker node는 그냥 일반 컴퓨터/서버 (에: EC2 인스턴스)
- kubernetes에서는 Pod를 실행하는 역할을 맡음
- Worker node는 태스크에 특화되지 않고, 다양한 포드(컨테이너)를 동시에 실행할 수 있다.

> 컨테이너를 돌리기 위해 CPU와 메모리를 제공하는 물리적 공간

5-2. Worker node 안에서 실행되는 것

구성 요소 | 설명
Pod(포드) | 컨테이너를 감싸는 단위. 포드 안에 컨테이너와 필요한 리소스(예: 볼륨)가 들어있음.
Docker(또는 컨테이너 런타임) | 실제 컨테이너를 실행시키는 프로그램. (Docker 외에 container 등을 쓸 수도 있음)
kubelet | 마스터 노드(Control Plane)와 통신하는 에이전트. 포드를 만들고 상태를 보고함.
kube-proxy | 네트워크 트래픽을 관리하는 컴포넌트. 포드와 외부 세계(또는 다른 포드) 간의 트래픽을 중개.

> 포드를 돌리기 위한 컨테이너 런타임 + 마스터와 통신하는 kubelet + 네트워크를 관리하는 kube-proxy

5-3. 비유하면

- 로컬에서 'docker run'으로 여러 컨테이너를 띄웠던 것처럼,
- 워커 노드도 여러 포드(컨테이너 집합) 를 동시에 띄움
- 단지 이 워커 노드는 클라우드에 있거나, 여러 서버에 분산될 수 있다는 차이만 있음

**역시 내부 동작을 이해하는 것이 중요하다.**

### 6. Master Node

> 마스터 노드는 API 서버, 스케줄러, 컨트롤러 매니저, 클라우드 컨트롤러 매니저로 구성되어 클러스터 전체를 지휘하고 유지

4-1. Mater Node란?

> 컨테이너를 띄우는 일꾼(워커 노드)들을 지휘하는 컨트롤 타워

- 클러스터 전체를 관리하고 조율하는 컨트롤 타워
- 포드를 만들고, 어디에 배치할지 결정하고, 상태를 모니터링
- 워커 노드와 직접 통신하는 핵심 역할을 맡음

4-2 마스터 노드 안에 있는 핵심 구성요소

구성 요소 | 역할 요약
API Server | 쿠버네티스의 입구. 워커 노드(kubelet)와 통신하고, 모든 명령과 요청을 처리한다.
Scheduler | 새로운 포드를 어디(어떤 워커 노드)에 띄울지 결정한다.
Controller Manager | 클러스터의 현재 상태를 모니터링하고, 목표 상태와 다르면 조정한다.
Cloud Controller Manager | 클라우드 리소스(AWS, Azure 등)와 연결해서 필요한 자원을 클라우드에 요청한다.

1. API Server

> 쿠버네티스의 통신센터

- 클러스터와 소통하는 공식 게이트웨이
- 외부 요청(kubectl 명령어, 관리 도구 요청 등)과 내부 통신(워커 노드와의 통신)을 모두 처리
- 모든 요청은 API 서버를 통해 들어오고, 나감

2. Scheduler

- 새 포드가 필요할 때, 어떤 워커 노드에 띄울지 선택
- CPU/메모리 여유, 노드 상태 등을 고려해서 최적의 노드를 고름

3. Controller Manager

> 상태를 목표와 동기화하는 관리자

- "지금 클러스터 상태가 목표 상태랑 같나?"를 계속 감시
- 만약 포드가 죽었거나, 노드가 다운됐다면, 새로운 포드를 만들어서 상태를 회복

4. Cloud Controller Manager

> 클라우드 리소스 조정사

- 클라우드 환경에서만 필요한 추가 요소
- 로드밸런서 생성, 스토리지 연결 등 클라우드 관련 작업을 처리
- 클라우드 벤더(AWS, Azure, GCP)에 맞게 API 호출을 번역

```
[Master Node] // 마스터가 명령을 내리고
 ├─ API Server (모든 요청의 입구)
 ├─ Scheduler (포드 배치 결정)
 ├─ Controller Manager (상태 모니터링 & 복구)
 └─ Cloud Controller Manager (클라우드 연동)

[Master Node] ↔ [Worker Node + kubelet] // 워커 노드가 명령을 따라 포드를 실행하고 둘 사이에 kubelet과 API Server가 통신한다.
```

7. Kubernetes 학습에 앞선 용어 정리

> 쿠버네티스는 클러스터-노드-포드-컨테이너 구조를 통해 애플리케이션을 배포하고, 서비스로 외부 연결을 관리한다.

용어 | 설명 요약
클러스터 (Cluster) | 마스터 노드 + 워커 노드들의 집합. kubernetes가 관리하는 하나의 시스템 단위.
노드 (Node) | 포드를 실행하는 실제 머신 (가상머신 또는 물리 서버).
마스터 노드 (Master Node) | 컨트롤 플레인. 클러스터 전체를 관리하고 워커 노드를 제어하는 역할.
워커 노드 (Worker Node) | 포드와 컨테이너를 직접 실행하는 일꾼 서버. CPU/메모리 리소스를 제공함.
포드 (Pod) | 컨테이너를 감싸는 단위 kubernetes에서 컨테이너를 직접 관리하지 않고 포드를 관리함.
컨테이너 (Container) | 실제 어플리케이션과 그 실행 환경을 담은 경량화된 독립 실행 단위. (ex: Docker 컨테이너)
서비스 (Service) | 포드를 외부에 노출시키기 위한 가상 IP 집합. 포드 집합에 안정적인 접근 포인트를 제공.

> kubernetes는 포드를 관리하고, 포드는 컨테이너를 실행한다.
> 서비스를 통해 포드에 접근할 수 있다.

7-1. GPT 식 비유

- 클러스터 = 회사
- 마스터 노드 = CEO
- 워커 노드 = 부서
- 포드 = 부서 안 팀
- 컨테이너 = 팀원이 하는 실제 일
- 서비스 = 회사 대표 전화번호 (→ 원하는 팀으로 연결해줌)
